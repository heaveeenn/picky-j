#!/usr/bin/env python3
"""
í€´ì¦ˆ ë²¡í„°í™” ìŠ¤í¬ë¦½íŠ¸ - MySQLì˜ í€´ì¦ˆ ë°ì´í„°ë¥¼ Qdrantì— ë²¡í„°í™”í•˜ì—¬ ì €ì¥
"""

import asyncio
import logging
import time
from typing import List, Dict, Optional
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from app.vectorization.embeddings import embedding_service
from app.vectorization.qdrant_client import QdrantService

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class QuizVectorizer:
    """í€´ì¦ˆ ë²¡í„°í™” ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.qdrant_service = QdrantService()
        self.collection_name = "quizzes"

        import os
        mysql_url = os.getenv("MYSQL_URL")
        if not mysql_url:
            raise ValueError("MYSQL_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if mysql_url.startswith("mysql://"):
            mysql_url = mysql_url.replace("mysql://", "mysql+pymysql://")

        self.engine = create_engine(mysql_url)
        self.SessionLocal = sessionmaker(bind=self.engine)

    def get_quiz_count(self) -> int:
        """ì „ì²´ í€´ì¦ˆ ê°œìˆ˜ ì¡°íšŒ"""
        session = self.SessionLocal()
        try:
            result = session.execute(text("SELECT COUNT(*) FROM quiz"))
            count = result.scalar()
            logger.info(f"ğŸ“Š ì „ì²´ í€´ì¦ˆ ê°œìˆ˜: {count:,}ê°œ")
            return count
        finally:
            session.close()

    def get_quizzes_batch(self, offset: int, limit: int) -> List[Dict]:
        """ë°°ì¹˜ë¡œ í€´ì¦ˆ ë°ì´í„° ì¡°íšŒ"""
        session = self.SessionLocal()
        try:
            query = text("""
                SELECT id, title, question, explanation
                FROM quiz
                ORDER BY id
                LIMIT :limit OFFSET :offset
            """)

            result = session.execute(query, {"limit": limit, "offset": offset})

            quizzes = []
            for row in result:
                quizzes.append({
                    "id": row[0],
                    "title": row[1] or "",
                    "question": row[2] or "",
                    "explanation": row[3] or ""
                })

            return quizzes

        except Exception as e:
            logger.error(f"âŒ í€´ì¦ˆ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        finally:
            session.close()

    def prepare_quiz_text(self, quiz_data: Dict) -> str:
        """í€´ì¦ˆ ë°ì´í„°ì—ì„œ ë²¡í„°í™”ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        title = quiz_data.get("title", "").strip()
        question = quiz_data.get("question", "").strip()
        explanation = quiz_data.get("explanation", "").strip()

        # Xë¬¸ì œ(explanation ìˆìŒ): title + explanation (ì˜¬ë°”ë¥¸ ì •ë³´)
        if explanation:
            return f"{title} {explanation}".strip()

        # Oë¬¸ì œ(explanation ì—†ìŒ): title + question (ì˜¬ë°”ë¥¸ ì •ë³´)
        else:
            return f"{title} {question}".strip()

    def build_metadata(self, quiz_data: Dict) -> Dict:
        """í€´ì¦ˆ ë©”íƒ€ë°ì´í„° ìƒì„± - quiz_idë§Œ ì €ì¥í•˜ì—¬ ìš©ëŸ‰ ìµœì í™”"""
        return {
            "quiz_id": quiz_data.get("id"),
            "embedding_version": "quiz-v1"
        }

    async def vectorize_and_save_batch(
        self,
        quizzes: List[Dict],
        batch_size: int = 32
    ) -> Dict[str, int]:
        """í€´ì¦ˆ ë°°ì¹˜ë¥¼ ë²¡í„°í™”í•˜ì—¬ Qdrantì— ì €ì¥"""

        stats = {"processed": len(quizzes), "embedded": 0, "skipped": 0}

        # í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        prepared_entries = []
        for quiz in quizzes:
            text = self.prepare_quiz_text(quiz)
            if not text or len(text.strip()) < 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ìŠ¤í‚µ
                stats["skipped"] += 1
                continue

            metadata = self.build_metadata(quiz)
            point_id = quiz["id"]
            prepared_entries.append((text, metadata, point_id))

        if not prepared_entries:
            return stats

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë²¡í„°í™” ë° ì €ì¥
        for start in range(0, len(prepared_entries), batch_size):
            chunk = prepared_entries[start:start + batch_size]

            texts = [entry[0] for entry in chunk]
            metadatas = [entry[1] for entry in chunk]
            point_ids = [entry[2] for entry in chunk]

            # ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3ë²ˆ)
            max_retries = 3
            retry_count = 0
            success = False

            while retry_count < max_retries and not success:
                try:
                    if not embedding_service:
                        raise RuntimeError("Embedding service is not available")

                    # ë²¡í„°í™”
                    vectors = await embedding_service.encode_batch(texts)

                    # Qdrantì— ì €ì¥
                    await self.qdrant_service.save_vectors_with_metadata_and_ids(
                        self.collection_name,
                        vectors,
                        metadatas,
                        point_ids
                    )

                    stats["embedded"] += len(chunk)
                    logger.info(f"âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(chunk)}ê°œ (ì´ {stats['embedded']}ê°œ)")
                    success = True

                except Exception as e:
                    retry_count += 1
                    if retry_count < max_retries:
                        wait_time = retry_count * 2  # 2ì´ˆ, 4ì´ˆ, 6ì´ˆ ëŒ€ê¸°
                        logger.warning(f"âš ï¸ ë°°ì¹˜ ì‹¤íŒ¨ (ì‹œë„ {retry_count}/{max_retries}): {e}")
                        logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ ë°°ì¹˜ ì €ì¥ ìµœì¢… ì‹¤íŒ¨ ({max_retries}ë²ˆ ì‹œë„): {e}")
                        stats["skipped"] += len(chunk)

        return stats

    async def vectorize_all_quizzes(self, batch_size: int = 1000, embed_batch_size: int = 32, max_quizzes: int = None):
        """ëª¨ë“  í€´ì¦ˆë¥¼ ë²¡í„°í™”"""
        logger.info("ğŸš€ í€´ì¦ˆ ë²¡í„°í™” ì‹œì‘")
        start_time = time.time()

        # ì „ì²´ ê°œìˆ˜ í™•ì¸
        total_count = self.get_quiz_count()
        if total_count == 0:
            logger.warning("âŒ ì²˜ë¦¬í•  í€´ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ
        if max_quizzes and max_quizzes < total_count:
            total_count = max_quizzes
            logger.info(f"ğŸ”¢ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ: {max_quizzes:,}ê°œë¡œ ì„¤ì •")

        # ì»¬ë ‰ì…˜ ìƒì„± í™•ì¸
        try:
            self.qdrant_service.create_collection_if_not_exists(
                self.collection_name,
                vector_size=1536
            )
            logger.info(f"âœ… Qdrant ì»¬ë ‰ì…˜ '{self.collection_name}' ì¤€ë¹„ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ Qdrant ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return

        # í†µê³„ ì´ˆê¸°í™”
        total_embedded = 0
        total_skipped = 0

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for offset in range(0, total_count, batch_size):
            batch_num = (offset // batch_size) + 1
            total_batches = (total_count + batch_size - 1) // batch_size

            logger.info(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... (offset: {offset})")

            # í€´ì¦ˆ ë°ì´í„° ì¡°íšŒ
            quizzes = self.get_quizzes_batch(offset, batch_size)
            if not quizzes:
                logger.warning(f"âš ï¸ ë°°ì¹˜ {batch_num}: ë°ì´í„° ì—†ìŒ")
                continue

            # ë²¡í„°í™” ë° ì €ì¥
            stats = await self.vectorize_and_save_batch(quizzes, embed_batch_size)

            total_embedded += stats["embedded"]
            total_skipped += stats["skipped"]

            # ì§„í–‰ë¥  ì¶œë ¥
            progress = (offset + len(quizzes)) / total_count * 100
            logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% | ì„ë² ë”©: {total_embedded:,}ê°œ | ìŠ¤í‚µ: {total_skipped:,}ê°œ")

            # ë°°ì¹˜ê°„ ì§§ì€ ëŒ€ê¸° (API ì„œë²„ ë¶€ë‹´ ì™„í™”)
            await asyncio.sleep(0.1)

        # ì™„ë£Œ í†µê³„
        total_time = time.time() - start_time
        logger.info("=" * 60)
        logger.info("ğŸ‰ í€´ì¦ˆ ë²¡í„°í™” ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        logger.info(f"   - ì „ì²´ í€´ì¦ˆ: {total_count:,}ê°œ")
        logger.info(f"   - ë²¡í„°í™” ì„±ê³µ: {total_embedded:,}ê°œ")
        logger.info(f"   - ìŠ¤í‚µ: {total_skipped:,}ê°œ")
        logger.info(f"   - ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ")
        logger.info(f"   - ì²˜ë¦¬ ì†ë„: {total_embedded/total_time:.1f}ê°œ/ì´ˆ")
        logger.info("=" * 60)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        vectorizer = QuizVectorizer()
        await vectorizer.vectorize_all_quizzes(
            batch_size=1000,
            embed_batch_size=32,
            max_quizzes=10000
        )
    except Exception as e:
        logger.error(f"âŒ í€´ì¦ˆ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())